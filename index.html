<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Hybrid Imitation - Reinforcement Learning for Xpilot - Muhammad Abdullah (COM 407)</title>

  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;700&display=swap" rel="stylesheet">

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha512-pap3X...replaceWithFullHash..." crossorigin="anonymous" referrerpolicy="no-referrer" />
  <link rel="stylesheet" href="style.css">
  <style>html { scroll-behavior: smooth; }</style>
</head>


<body>
  <header class="site-header">
    <div class="container nav-wrap">
      <a class="brand" href="#home">
        <span class="logo">üåê</span>
        <span class="brand-text">Muhammad Abdullah - COM 407</span>


      </a>

      <input id="nav-toggle" type="checkbox" class="nav-toggle" />
      <label for="nav-toggle" class="nav-toggle-label" aria-hidden="true">
        <span></span>
      </label>



      <nav class="nav">
        <a href="#home"><i class="fa fa-house"></i> Home</a>
        <a href="#overview"><i class="fa fa-book-open"></i> Overview</a>
        <a href="#methods"><i class="fa fa-cogs"></i> Methodology</a>
        <a href="#results"><i class="fa fa-chart-line"></i> Results</a>
        <a href="#future"><i class="fa fa-lightbulb"></i> Future Work</a>
        <a href="#contact"><i class="fa fa-envelope"></i> Contact</a>
      </nav>
    </div>
  </header>

  <!-- HERO -->
  <main>
    <section id="home" class="hero">
      <div class="container hero-grid">
        <div class="hero-text">

          <h1>Hybrid Imitation - Reinforcement Learning for Xpilot</h1>
          <p class="subtitle">A hybrid pipeline to train an autonomous agent using imitation learning followed by reinforcement fine-tuning - <strong>COM 407</strong></p>
          <p>

            This project combines behavior cloning from demonstrations with Deep Q-Learning fine-tuning so the agent learns basic control from examples and improves with experience.
          </p>

          <p class="hero-ctas">
            <a class="btn" href="#overview">View Project Details</a>


            <a class="btn btn-outline" href="proposal.pdf" download>View Proposal (PDF)</a>
          </p>
        </div>

        <div class="hero-media">

          <img src="images/agent_demo.gif" alt="Agent demo GIF (placeholder)" />
          <figcaption class="caption">_</figcaption>
        </div>
      </div>
    </section>

    <section id="overview" class="section">

      <div class="container">
        <h2><i class="fa fa-book-open"></i> Overview</h2>
        <p class="lead">
          <strong>Motivation:</strong> Pure reinforcement learning can be slow to train. Imitation learning provides an initial policy and reinforcement fine-tuning improves that policy further. This hybrid approach leverages structured-state inputs to speed up learning and keep training stable.
        </p>

        <h3>Objectives</h3>
        <ul class="feature-list">

          <li><i class="fa fa-dot-circle"></i> Record demonstration data and build a behavior cloning baseline.</li>
          <li><i class="fa fa-dot-circle"></i> Implement and train a DQN initialized from the imitation model to fine-tune performance.</li>
          <li><i class="fa fa-dot-circle"></i> Evaluate and visualize performance for rule-based, imitation-only, and hybrid agents.</li>
        </ul>

        <div class="flow">
          <strong>Idea flow:</strong>


          <span>Environment -&gt; Structured State -&gt; Imitation Model -&gt; DQN Fine-tuning -&gt; Actions -&gt; Rewards -&gt; Improved Policy</span>
        </div>
      </div>


    </section>

    <section id="methods" class="section alt">
      <div class="container">
        <h2><i class="fa fa-cogs"></i> Methodology</h2>



        <h3>Environment design</h3>
        <p>
          The environment is a 2D continuous arena with the agent, enemies, projectiles, and walls. Episodes end on agent death or a fixed time limit. An environment wrapper provides a normalized structured state and accepts discrete actions.
        </p>

        <h3>Structured-state representation</h3>
        <p>
          Observations are fixed-length numeric vectors: agent state <code>x, y, v, theta</code>, nearest N enemies (relative dx, dy, dist, heading), nearest M bullets (dx, dy, dist, vel, heading), and wall distances.
        </p>

        <h3>Imitation and DQN pipeline</h3>
        <p>
          First the agent is trained with supervised behavior cloning on demonstration recordings. The same network architecture is used to initialize a Deep Q-Network for reinforcement fine-tuning. DQN training uses experience replay, a target network, epsilon-greedy exploration, and Double DQN updates.
        </p>

        <div class="two-col">
          <div>
            <h4>Key hyperparameters</h4>
            <ul>
              <li><i class="fa fa-check"></i> Learning rate: still loading</li>
              <li><i class="fa fa-check"></i> Batch size: still loading</li>

              <li><i class="fa fa-check"></i> Discount (gamma): still loading</li>
            </ul>
          </div>
          <div>
            <h4>Evaluation</h4>
            <ul>
              <li><i class="fa fa-check"></i> Average survival time</li>
              <li><i class="fa fa-check"></i> Episode reward</li>
            </ul>
          </div>

        </div>


      </div>
    </section>

    <section id="results" class="section">
      <div class="container">
        <h2><i class="fa fa-chart-line"></i> Results</h2>

        <p class="lead">Summary of findings</p>

        <ul class="result-list">
          <li><strong>Imitation baseline:</strong> Still Loading</li>
          <li><strong>DQN fine-tuning:</strong> Still Loading</li>
        </ul>

        <div class="results-grid">
          <figure>
            <img src="images/learning_curve.png" alt="Learning curve placeholder" />
            <figcaption>Still Loading</figcaption>
          </figure>
          
          <figure>
            <img src="images/learning_curve.png" alt="Learning curve placeholder" />
            <figcaption>Still Loading</figcaption>
          </figure>

          <figure>
            <img src="images/learning_curve.png" alt="Learning curve placeholder" />
            <figcaption>Still Loading</figcaption>
          </figure>
        </div>
      </div>
    </section>

    <section id="future" class="section alt">
      <div class="container">
        <h2><i class="fa fa-lightbulb"></i> Future Work</h2>
        <ol>
          <li>Still Loading</li>
          <li>Still Loading</li>
          <li>Still Loading</li>
        </ol>
      </div>
    </section>

    <section id="contact" class="section contact">
      <div class="container">
        <h2><i class="fa fa-envelope"></i> Contact</h2>
        <p><strong>Muhammad Abdullah</strong><br/>COM 407 @ Connecticut College</p>
        <p>Email: <a href="mailto:mabdullah@conncoll.edu">mabdullah@conncoll.edu</a></p>
        <p>
          GitHub: <a href="https://github.com/mabdullah1010" target="_blank" rel="noopener">github.com/mabdullah1010</a>
          &nbsp;‚Ä¢&nbsp;
          LinkedIn: <a href="https://www.linkedin.com/in/iammuhammadabdullah" target="_blank" rel="noopener">https://www.linkedin.com/in/iammuhammadabdullah/</a>
        </p>
      </div>
    </section>
  </main>

  <footer class="site-footer">
    <div class="container">
      <small>¬© Muhammad Abdullah (COM 407) ‚Ä¢ Project showcase</small>
    </div>
  </footer>

</body>
</html>
